# RAGcipies ü•£

RAGcipies es un sistema de Retrieval-Augmented Generation (RAG) que utiliza b√∫squeda vectorial sem√°ntica para encontrar recetas de cocina bas√°ndose en consultas en lenguaje natural como:

- "cena vegana con garbanzos"
- "algo dulce sin huevos"
- "comida r√°pida con arroz"

El sistema almacena una colecci√≥n de recetas, las convierte en embeddings, las inserta en una base de datos vectorial, recupera los resultados m√°s relevantes sem√°nticamente, y usa un LLM para generar una respuesta √∫til basada en el contexto recuperado.

## üéØ Objetivos Principales

- Aprender e implementar un pipeline RAG minimalista y limpio
- Usar b√∫squeda vectorial para encontrar recetas relevantes
- Usar un LLM para formatear y generar la respuesta final

## üß† ¬øQu√© es RAG y qu√© problema resuelve?

**RAG (Retrieval-Augmented Generation)** es un patr√≥n de arquitectura para LLMs que combina:

1. **Recuperaci√≥n de informaci√≥n** desde una base de conocimiento externa (vector store, base de datos, archivos, etc.).
2. **Generaci√≥n con un modelo de lenguaje (LLM)** usando esa informaci√≥n como contexto.

La idea central es:

> El LLM **no inventa** la respuesta, sino que **lee primero** desde una fuente confiable y despu√©s genera la respuesta usando ese contexto.

### ¬øPor qu√© es √∫til en un proyecto de recetas?

Un LLM ‚Äúpuro‚Äù solo conoce recetas que vio durante su entrenamiento.  
No sabe nada sobre:

- Recetas nuevas creadas por el usuario.
- Recetas privadas almacenadas en un JSON local.
- Recetas con formatos o combinaciones espec√≠ficas que no existen en Internet.

Si le ped√≠s, por ejemplo:

> "tarta de pollo con masa de avena y curry"

y esa receta solo existe en nuestro recetario, un LLM sin RAG:

- puede **alucinar** (inventar una receta parecida),
- o puede devolver algo gen√©rico que no coincide con tu dataset.

Con RAG, el flujo cambia:

1. La pregunta del usuario se convierte en un embedding.
2. Se busca en el **vector store** de recetas las m√°s parecidas sem√°nticamente.
3. Se recuperan las recetas relevantes.
4. El LLM genera la respuesta **basado en esas recetas reales**.

De esta forma:

- RAGcipies puede trabajar con **recetas que no exist√≠an cuando se entren√≥ el modelo**.
- Se soportan **recetas privadas y personalizadas**.
- Se reducen las **alucinaciones**, porque el modelo se apoya en evidencia real (las recetas del dataset).

## üîÅ Flujo de trabajo

```
(1) Pregunta del usuario
        ‚îÇ
        ‚ñº
(2) Embedding de la query (EmbeddingModel)
        ‚îÇ
        ‚ñº
(3) B√∫squeda vectorial (VectorStore.search ‚Üí top-k chunks)
        ‚îÇ
        ‚ñº
(4) Armado de contexto + prompt (build_prompt)
        ‚îÇ
        ‚ñº
(5) LLM (LLMClient.generate)
        ‚îÇ
        ‚ñº
(6) Respuesta final al usuario

```

### üîç 1. Pregunta del usuario

El usuario env√≠a una consulta en lenguaje natural.
Ejemplo:

> ‚ÄúQuiero una receta con pollo y arroz‚Äù

Este texto es la entrada principal al flujo RAG.

### üßÆ 2. Embedding de la query (EmbeddingModel)

La pregunta del usuario se convierte en un **vector num√©rico** mediante un modelo de embeddings. 

**¬øQu√© es un embedding?**
Un embedding es una representaci√≥n matem√°tica del significado de un texto. Transforma palabras y frases en vectores (listas de n√∫meros) que capturan la sem√°ntica del contenido.

Ejemplo:

```
"Pollo al curry" ‚Üí [0.02, -0.11, 0.79, 0.45, -0.23, 0.67, ...]
"Pollo con curry" ‚Üí [0.03, -0.10, 0.78, 0.44, -0.22, 0.66, ...]  (similar)
"Ensalada de frutas" ‚Üí [0.91, 0.23, -0.45, 0.12, 0.88, -0.34, ...]  (diferente)
```

**¬øC√≥mo funciona?**
Los embeddings operan en un "espacio sem√°ntico" donde:
- **Textos similares** (como "pollo al curry" y "pollo con curry") tienen vectores **cercanos** entre s√≠.
- **Textos diferentes** (como "pollo al curry" y "ensalada de frutas") tienen vectores **lejos** entre s√≠.

Esta propiedad permite buscar informaci√≥n por **similitud sem√°ntica** en lugar de solo coincidencias exactas de palabras.

**En el flujo RAG:**
El embedding de la consulta se usa para encontrar las recetas m√°s relevantes en el vector store mediante b√∫squeda por similitud (similarity search), que es el siguiente paso del pipeline.

### üß≠ 3. B√∫squeda vectorial (VectorStore.search)

El vector de la query se compara con los embeddings de todas las recetas almacenadas.
El vector store calcula la similitud (por ejemplo, cosine similarity) y devuelve los **top-k** documentos m√°s relevantes.

```
1. Pollo con arroz (score 0.95)
2. Arroz con pollo al horno (score 0.88)
3. Arroz con verduras (score 0.61)
```

### üß± 4. Armado del contexto + prompt (build_prompt)

El sistema arma un prompt que incluye:
- instrucciones para el modelo,
- los chunks/documentos recuperados,
- la pregunta original del usuario.

```
Usa el siguiente contexto para responder la pregunta:

[score=0.95]
Receta: Pollo con arroz...
Ingredientes...
Instrucciones...

Pregunta del usuario: "Quiero una receta con pollo y arroz"

```

### ü§ñ 5. LLM (LLMClient.generate)

El prompt se env√≠a al modelo de lenguaje (LLM).
El LLM genera una respuesta utilizando:

- el contexto recuperado,
- su conocimiento general,
- y la pregunta del usuario.

Si se usa `DummyLLM`, la respuesta es un placeholder para pruebas.
Cuando se integre un LLM real, producir√° recetas completas y relevantes.

### üìù 6. Respuesta final al usuario

El pipeline retorna la respuesta del LLM, por ejemplo:

> "Pod√©s preparar un pollo con arroz salteado con ajo y cebolla.
> Aqu√≠ ten√©s una receta basada en el contexto recuperado‚Ä¶"

Este es el resultado final para mostrar en una API, notebook o interfaz.














## üîó Links

### RAG (Retrieval-Augmented Generation)

- [IBM - Retrieval-Augmented Generation](https://www.ibm.com/think/topics/retrieval-augmented-generation)
- [Google Cloud - RAG Use Cases](https://cloud.google.com/use-cases/retrieval-augmented-generation)
- [NVIDIA Blog - What is RAG?](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/)

### Embeddings

#### OpenAI Embeddings (Documentaci√≥n Oficial)

- [OpenAI API Reference - Embeddings](https://platform.openai.com/docs/api-reference/embeddings) - Especificaci√≥n completa de la API, par√°metros y modelos disponibles
- [OpenAI Python SDK](https://github.com/openai/openai-python) - Repositorio oficial del SDK de Python
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings) - Gu√≠a pr√°ctica de uso y mejores pr√°cticas
- [OpenAI Models - Embeddings](https://platform.openai.com/docs/models/embeddings) - Modelos de embeddings disponibles (text-embedding-3-small, text-embedding-3-large, etc.)
- [OpenAI Cookbook - Embeddings](https://cookbook.openai.com/examples/how_to_get_embeddings) - Ejemplos pr√°cticos y casos de uso
- [OpenAI Cookbook Repository](https://github.com/openai/openai-cookbook) - Repositorio con ejemplos, notebooks y tutoriales